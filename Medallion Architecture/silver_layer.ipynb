{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78b0d9b2-4284-4a0b-81ed-639a95789bd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# âœ¨ USE YOUR REAL VALUES BELOW\n",
    "\n",
    "client_id      = \"\"     # Application (client) ID\n",
    "tenant_id      = \"\"      # Directory (tenant) ID\n",
    "client_secret  = \"\"          # Client Secret (Value)\n",
    "\n",
    "storage_account = \"azuresupply2605\"\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\",\n",
    "               \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", client_secret)\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\",\n",
    "               f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0888eb95-89e4-4c5c-9f0f-c2f461e00435",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "external_bronze = spark.read.parquet(\n",
    "    \"abfss://bronze@azuresupply2605.dfs.core.windows.net/external/\"\n",
    ")\n",
    "\n",
    "feature_bronze = spark.read.parquet(\n",
    "    \"abfss://bronze@azuresupply2605.dfs.core.windows.net/feature/\"\n",
    ")\n",
    "\n",
    "demand_bronze = spark.read.parquet(\n",
    "    \"abfss://bronze@azuresupply2605.dfs.core.windows.net/demand/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad983486-d1cc-48d1-9b7b-0ad1c157affd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_columns(df):\n",
    "    for col_name in df.columns:\n",
    "        df = df.withColumnRenamed(col_name, col_name.lower().replace(\" \", \"_\"))\n",
    "    return df\n",
    "\n",
    "external_silver = clean_columns(external_bronze)\n",
    "feature_silver = clean_columns(feature_bronze)\n",
    "demand_silver = clean_columns(demand_bronze)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13c9a37a-b3ee-47ca-9a39-aab83af2fcdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "external_silver = external_silver.dropDuplicates()\n",
    "feature_silver = feature_silver.dropDuplicates()\n",
    "demand_silver = demand_silver.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c266b608-d985-457a-a211-ef2cb41f934e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "for df in [external_silver, feature_silver, demand_silver]:\n",
    "    for c in df.columns:\n",
    "        if \"date\" in c or \"month\" in c:\n",
    "            df = df.withColumn(c, to_date(col(c)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afac9e6d-a012-4345-9f02-89dd9f6bc921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, NumericType\n",
    "\n",
    "def fill_missing(df):\n",
    "    for field in df.schema.fields:\n",
    "        if isinstance(field.dataType, NumericType):\n",
    "            df = df.fillna({field.name: 0})\n",
    "        elif isinstance(field.dataType, StringType):\n",
    "            df = df.fillna({field.name: \"Unknown\"})\n",
    "    return df\n",
    "\n",
    "external_silver = fill_missing(external_silver)\n",
    "feature_silver = fill_missing(feature_silver)\n",
    "demand_silver = fill_missing(demand_silver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f3f7b0b-8ff8-4cef-84e5-302cdd0edceb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "external_silver.write.mode(\"overwrite\").parquet(\n",
    "    \"abfss://silver@azuresupply2605.dfs.core.windows.net/external/\"\n",
    ")\n",
    "\n",
    "feature_silver.write.mode(\"overwrite\").parquet(\n",
    "    \"abfss://silver@azuresupply2605.dfs.core.windows.net/feature/\"\n",
    ")\n",
    "\n",
    "demand_silver.write.mode(\"overwrite\").parquet(\n",
    "    \"abfss://silver@azuresupply2605.dfs.core.windows.net/demand/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "518ab47b-de9e-4886-a118-d09d29a9975e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- cloud_demand_index: integer (nullable = false)\n",
      " |-- gdp_growth: double (nullable = false)\n",
      " |-- inflation: double (nullable = false)\n",
      " |-- competitor_price_index: integer (nullable = false)\n",
      "\n",
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- region: string (nullable = false)\n",
      " |-- service: string (nullable = false)\n",
      " |-- daily_usage_units: integer (nullable = false)\n",
      " |-- peak_usage_units: integer (nullable = false)\n",
      " |-- vm_count: integer (nullable = false)\n",
      " |-- storage_tb: integer (nullable = false)\n",
      " |-- season: string (nullable = false)\n",
      " |-- econ_index: integer (nullable = false)\n",
      " |-- downtime_min: integer (nullable = false)\n",
      " |-- usage_lag_1: double (nullable = false)\n",
      " |-- usage_lag_7: double (nullable = false)\n",
      " |-- week_over_week_growth: double (nullable = false)\n",
      " |-- seasonality_factor: double (nullable = false)\n",
      "\n",
      "root\n",
      " |-- daily_usage_units: integer (nullable = false)\n",
      " |-- date: date (nullable = true)\n",
      " |-- downtime_min: integer (nullable = false)\n",
      " |-- econ_index: integer (nullable = false)\n",
      " |-- peak_usage_units: integer (nullable = false)\n",
      " |-- region: string (nullable = false)\n",
      " |-- season: string (nullable = false)\n",
      " |-- service: string (nullable = false)\n",
      " |-- storage_tb: integer (nullable = false)\n",
      " |-- vm_count: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "external_silver.printSchema()\n",
    "feature_silver.printSchema()\n",
    "demand_silver.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "470ab6f1-e13c-4a96-afc3-f2e7ea2f7a60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
